{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title 1. Install Necessary Libraries\n",
        "# Using the older azure-ai-formrecognizer SDK for ADI as per original user function\n",
        "!pip install --upgrade --quiet azure-ai-formrecognizer azure-identity\n",
        "# Newer ADI SDK (optional, but good practice for future reference)\n",
        "# !pip install --upgrade --quiet azure-ai-documentintelligence\n",
        "!pip install --upgrade --quiet langchain langchain-community langchain-openai langchain-core pydantic\n",
        "!pip install --upgrade --quiet requests # General HTTP requests\n",
        "!pip install --upgrade --quiet openai azure-ai-formrecognizer azure-identity requests\n",
        "!pip install --upgrade --quiet openai azure-ai-formrecognizer azure-identity requests"
      ],
      "metadata": {
        "id": "_f9SzLTle_h-",
        "collapsed": true
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Import Libraries\n",
        "import os\n",
        "import json\n",
        "from google.colab import files # Import for file uploads\n",
        "import io                      # Import for creating byte streams\n",
        "import base64                  # Import for base64 encoding\n",
        "import mimetypes               # Import for detecting image type\n",
        "from google.colab import userdata\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "from azure.ai.formrecognizer import DocumentAnalysisClient # For ADI function\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "import warnings"
      ],
      "metadata": {
        "id": "LBHYV5ejfBoi"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. Configure Credentials using Colab Userdata\n",
        "\n",
        "# --- Retrieve Credentials ---\n",
        "try:\n",
        "    # Azure Document Intelligence Credentials\n",
        "    adi_endpoint = userdata.get('ENDPOINT')         # Your ADI Endpoint\n",
        "    adi_key = userdata.get('APIKEY')                # Your ADI Key\n",
        "\n",
        "    # Azure OpenAI Credentials\n",
        "    openai_endpoint = userdata.get('AZURE_ENDPOINT')      # Your Azure OpenAI Endpoint\n",
        "    openai_key = userdata.get('AZURE_OPENAI_KEY')   # Your Azure OpenAI Key\n",
        "    openai_deployment = userdata.get('DEPLOYMENT')        # Your GPT-4o Deployment Name in Azure AI Studio\n",
        "\n",
        "    # --- Define Static Config ---\n",
        "    openai_api_version = userdata.get('API_VERSION')      # API version supporting GPT-4o vision\n",
        "\n",
        "    # --- Validation ---\n",
        "    if not all([adi_endpoint, adi_key, openai_endpoint, openai_key, openai_deployment]):\n",
        "        missing = [\n",
        "            \"ENDPOINT (ADI)\" if not adi_endpoint else None,\n",
        "            \"APIKEY (ADI)\" if not adi_key else None,\n",
        "            \"AZURE_ENDPOINT (OpenAI)\" if not openai_endpoint else None,\n",
        "            \"AZURE_OPENAI_KEY (OpenAI)\" if not openai_key else None,\n",
        "            \"DEPLOYMENT (OpenAI)\" if not openai_deployment else None,\n",
        "        ]\n",
        "        missing_str = \", \".join(filter(None, missing))\n",
        "        raise ValueError(f\"One or more secrets are missing from Colab Userdata: {missing_str}\")\n",
        "\n",
        "    print(\"Credentials retrieved successfully from Colab Userdata.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error retrieving credentials: {e}\")\n",
        "    # Stop execution if credentials are not loaded properly\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3ccZl_4fOuA",
        "outputId": "39da0c02-a1d0-4939-fca1-b9cef1cd65fd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Credentials retrieved successfully from Colab Userdata.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "secret_name = 'DEPLOYMENT'\n",
        "\n",
        "# 2. Try to get the secret value\n",
        "secret_value = userdata.get(secret_name)\n",
        "\n",
        "# 3. Check if the value was retrieved (is not None)\n",
        "if secret_value is not None:\n",
        "    print(f\"✅ Success: Secret '{secret_name}' is accessible.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKK9Sz_UBoEJ",
        "outputId": "91cc893c-2f6d-48a4-82a4-366ae91f3183"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Success: Secret 'DEPLOYMENT' is accessible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eBkyDxzXpDRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Retrieve Credentials ---\n",
        "try:\n",
        "    # Azure Document Intelligence Credentials (for text extraction)\n",
        "    adi_endpoint = userdata.get('ENDPOINT')         # Your ADI Endpoint\n",
        "    adi_key = userdata.get('APIKEY')                # Your ADI Key\n",
        "\n",
        "    # Azure OpenAI Credentials (for key-value extraction)\n",
        "    openai_endpoint = userdata.get('AZURE_ENDPOINT')      # Your Azure OpenAI Endpoint\n",
        "    openai_key = userdata.get('AZURE_OPENAI_KEY')   # Your Azure OpenAI Key\n",
        "    openai_deployment_name = userdata.get('DEPLOYMENT')   # Your GPT-4o Deployment Name\n",
        "\n",
        "    # --- Define Static Config ---\n",
        "    openai_api_version = \"2024-05-01-preview\"      # API version supporting GPT-4o vision\n",
        "\n",
        "    # --- Validation ---\n",
        "    if not all([adi_endpoint, adi_key, openai_endpoint, openai_key, openai_deployment_name]):\n",
        "        missing = [\n",
        "            \"ENDPOINT (ADI)\" if not adi_endpoint else None,\n",
        "            \"APIKEY (ADI)\" if not adi_key else None,\n",
        "            \"AZURE_ENDPOINT (OpenAI)\" if not openai_endpoint else None,\n",
        "            \"AZURE_OPENAI_KEY (OpenAI)\" if not openai_key else None,\n",
        "            \"DEPLOYMENT (OpenAI)\" if not openai_deployment_name else None,\n",
        "        ]\n",
        "        missing_str = \", \".join(filter(None, missing))\n",
        "        raise ValueError(f\"One or more secrets are missing from Colab Userdata: {missing_str}\")\n",
        "\n",
        "    print(\"Credentials retrieved successfully from Colab Userdata.\")\n",
        "\n",
        "    # --- Initialize Azure OpenAI Client ---\n",
        "    # Use the direct openai library client configured for Azure\n",
        "    openai_client = openai.AzureOpenAI(\n",
        "        api_key=openai_key,\n",
        "        azure_endpoint=openai_endpoint,\n",
        "        api_version=openai_api_version\n",
        "        # deployment_name is specified during the call, not usually at client init\n",
        "    )\n",
        "    print(\"Azure OpenAI client initialized.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during credential retrieval or client initialization: {e}\")\n",
        "    openai_client = None # Ensure client is None if setup fails\n",
        "    # Stop execution if credentials are not loaded properly\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92he4sKipOIq",
        "outputId": "10220b38-b0c3-4f8a-dfc2-b5c2ebb8d514"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Credentials retrieved successfully from Colab Userdata.\n",
            "Azure OpenAI client initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y7ol5pWY1bgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Azure Document Intelligence Credentials (for layout/text extraction)\n",
        "    adi_endpoint = userdata.get('ENDPOINT')         # Your ADI Endpoint\n",
        "    adi_key = userdata.get('APIKEY')                # Your ADI Key\n",
        "\n",
        "    # Azure OpenAI Credentials (for key-value extraction)\n",
        "    openai_endpoint = userdata.get('AZURE_ENDPOINT')      # Your Azure OpenAI Endpoint\n",
        "    openai_key = userdata.get('AZURE_OPENAI_KEY')   # Your Azure OpenAI Key\n",
        "    openai_deployment_name = userdata.get('DEPLOYMENT')   # Your GPT-4o Deployment Name\n",
        "\n",
        "    # --- Define Static Config ---\n",
        "    openai_api_version = \"2024-05-01-preview\"      # API version supporting GPT-4o vision\n",
        "\n",
        "    # --- Validation ---\n",
        "    if not all([adi_endpoint, adi_key, openai_endpoint, openai_key, openai_deployment_name]):\n",
        "        missing = [\n",
        "            \"ENDPOINT (ADI)\" if not adi_endpoint else None,\n",
        "            \"APIKEY (ADI)\" if not adi_key else None,\n",
        "            \"AZURE_ENDPOINT (OpenAI)\" if not openai_endpoint else None,\n",
        "            \"AZURE_OPENAI_KEY (OpenAI)\" if not openai_key else None,\n",
        "            \"DEPLOYMENT (OpenAI)\" if not openai_deployment_name else None,\n",
        "        ]\n",
        "        missing_str = \", \".join(filter(None, missing))\n",
        "        raise ValueError(f\"One or more secrets are missing from Colab Userdata: {missing_str}\")\n",
        "\n",
        "    print(\"Credentials retrieved successfully from Colab Userdata.\")\n",
        "\n",
        "    # --- Initialize Azure OpenAI Client ---\n",
        "    # Use the direct openai library client configured for Azure\n",
        "    openai_client = openai.AzureOpenAI(\n",
        "        api_key=openai_key,\n",
        "        azure_endpoint=openai_endpoint,\n",
        "        api_version=openai_api_version\n",
        "    )\n",
        "    print(\"Azure OpenAI client initialized.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during credential retrieval or client initialization: {e}\")\n",
        "    openai_client = None # Ensure client is None if setup fails\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4_a8aJA1ksM",
        "outputId": "c7f1541c-e5c4-4520-f82e-7845e32bfcc4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Credentials retrieved successfully from Colab Userdata.\n",
            "Azure OpenAI client initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. Upload Image File\n",
        "print(\"Please upload the image file you want to analyze.\")\n",
        "uploaded_files = files.upload()\n",
        "\n",
        "# --- Process Upload ---\n",
        "uploaded_filename = None\n",
        "uploaded_content = None # Bytes of the file\n",
        "image_bytes = None      # Alias for clarity\n",
        "image_mime_type = None\n",
        "\n",
        "if not uploaded_files:\n",
        "    print(\"\\nNo file uploaded. Please run this cell again and upload a file.\")\n",
        "    raise SystemExit(\"No file uploaded.\")\n",
        "elif len(uploaded_files) > 1:\n",
        "    print(\"\\nWarning: Multiple files uploaded. Using the first file.\")\n",
        "    uploaded_filename = next(iter(uploaded_files))\n",
        "    uploaded_content = uploaded_files[uploaded_filename]\n",
        "else:\n",
        "    uploaded_filename = next(iter(uploaded_files))\n",
        "    uploaded_content = uploaded_files[uploaded_filename]\n",
        "\n",
        "if uploaded_content:\n",
        "    image_bytes = uploaded_content\n",
        "    print(f\"\\nSuccessfully uploaded: '{uploaded_filename}' ({len(image_bytes)} bytes)\")\n",
        "    image_mime_type, _ = mimetypes.guess_type(uploaded_filename)\n",
        "    if image_mime_type is None:\n",
        "        image_mime_type = \"application/octet-stream\"\n",
        "        print(f\"Warning: Could not determine MIME type, using default: {image_mime_type}\")\n",
        "    elif not image_mime_type.startswith('image/'):\n",
        "        print(f\"\\nWarning: Uploaded file '{uploaded_filename}' might not be an image (detected type: {image_mime_type}). Processing anyway.\")\n",
        "    else:\n",
        "         print(f\"Detected MIME type: {image_mime_type}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "G3KCAkUW1nr9",
        "outputId": "c43126d3-58b7-420e-a2ac-84da50a3b7c3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload the image file you want to analyze.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1fff4bac-6a2e-4b3a-9c86-f151b30f4068\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1fff4bac-6a2e-4b3a-9c86-f151b30f4068\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving image 2.png to image 2.png\n",
            "\n",
            "Successfully uploaded: 'image 2.png' (310711 bytes)\n",
            "Detected MIME type: image/png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 5. Extract Text using Azure Document Intelligence (Layout Model)\n",
        "\n",
        "def extract_text_with_adi_layout(image_stream, endpoint, key):\n",
        "    \"\"\"\n",
        "    Extracts concatenated text content using ADI 'prebuilt-layout' model\n",
        "    from an in-memory image stream by iterating through lines.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Starting Azure Document Intelligence Layout Text Extraction ---\")\n",
        "    if not endpoint or not key:\n",
        "        print(\"Error: ADI Endpoint or Key is missing.\")\n",
        "        return \"Error: ADI Credentials missing.\"\n",
        "    if not image_stream:\n",
        "         print(\"Error: Image stream is missing.\")\n",
        "         return \"Error: Image stream missing.\"\n",
        "\n",
        "    try:\n",
        "        document_analysis_client = DocumentAnalysisClient(\n",
        "            endpoint=endpoint,\n",
        "            credential=AzureKeyCredential(key)\n",
        "        )\n",
        "        print(\"Analyzing document stream using 'prebuilt-layout' model...\")\n",
        "        poller = document_analysis_client.begin_analyze_document(\n",
        "            \"prebuilt-layout\",  # *** Use layout model ***\n",
        "            document=image_stream\n",
        "        )\n",
        "        result = poller.result()\n",
        "        print(\"ADI layout analysis complete.\")\n",
        "\n",
        "        # --- Reconstruct text from layout results ---\n",
        "        extracted_lines = []\n",
        "        if result.pages:\n",
        "            for page in result.pages:\n",
        "                if page.lines: # Check if lines exist for the page\n",
        "                    for line in page.lines:\n",
        "                        extracted_lines.append(line.content) # Add content of each line\n",
        "\n",
        "        # Join lines with newline characters to form the text block\n",
        "        full_text = \"\\n\".join(extracted_lines)\n",
        "\n",
        "        if full_text:\n",
        "            print(f\"Extracted {len(full_text)} characters of text from layout.\")\n",
        "            return full_text\n",
        "        else:\n",
        "            print(\"No text lines found by ADI layout model.\")\n",
        "            return \"\" # Return empty string if no content\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during ADI layout text extraction: {e}\")\n",
        "        return f\"Error during ADI layout text extraction: {str(e)}\"\n",
        "\n",
        "# --- Execute ADI Layout Text Extraction ---\n",
        "extracted_text = \"\"\n",
        "if image_bytes:\n",
        "    try:\n",
        "        image_byte_stream_for_adi = io.BytesIO(image_bytes)\n",
        "        # *** Call the updated function ***\n",
        "        extracted_text = extract_text_with_adi_layout(image_byte_stream_for_adi, adi_endpoint, adi_key)\n",
        "        if extracted_text.startswith(\"Error:\"):\n",
        "            print(f\"ADI layout step failed: {extracted_text}\")\n",
        "            print(\"Proceeding to GPT-4o without extracted text context.\")\n",
        "            extracted_text = \"\"\n",
        "    finally:\n",
        "        if 'image_byte_stream_for_adi' in locals() and not image_byte_stream_for_adi.closed:\n",
        "            image_byte_stream_for_adi.close()\n",
        "else:\n",
        "    print(\"Skipping ADI layout text extraction, no image content available.\")\n",
        "    extracted_text = \"Analysis skipped due to missing image.\"\n",
        "\n",
        "\n",
        "# Display first 500 chars of extracted text for verification\n",
        "print(\"\\n--- Extracted Text Context (Layout Model - First 500 Chars) ---\")\n",
        "print(extracted_text[:4070] + (\"...\" if len(extracted_text) > 500 else \"\"))\n",
        "print(\"---------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSXD5rrG1uwI",
        "outputId": "b427073b-82ec-40c3-9918-b03fcf11a468",
        "collapsed": true
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Azure Document Intelligence Layout Text Extraction ---\n",
            "Analyzing document stream using 'prebuilt-layout' model...\n",
            "ADI layout analysis complete.\n",
            "Extracted 1484 characters of text from layout.\n",
            "\n",
            "--- Extracted Text Context (Layout Model - First 500 Chars) ---\n",
            "CURRICULUM VITAE\n",
            "Dear Sir/ Madam,\n",
            "I intend to apply a job in your company for Able Bodied Seaman position and I am ready to be positioned on\n",
            "board with route of voyage determined by the company. My data as follows:\n",
            "· PERSONAL DATA\n",
            "Full Name\n",
            "Boni Rustami\n",
            "Rank\n",
            "Cook\n",
            "Place, date of birth\n",
            "Samarinda, 10 Juni 1990\n",
            "Address\n",
            "JI Cempaka No 15, Samarinda\n",
            "Marital Status\n",
            "Married\n",
            "Nationality\n",
            "Indonesia\n",
            "Religion\n",
            "Moslem\n",
            "Telephone\n",
            "082931023940\n",
            "Email\n",
            "boni.rustami@cakemail.com\n",
            "· DOCUMENT TRAVELS\n",
            "Document\n",
            "Number\n",
            "Issued At\n",
            "Issued Date\n",
            "Expire Date\n",
            "Seaman Book\n",
            "F18273909\n",
            "Samarinda\n",
            "18 Sep 2019\n",
            "18 Sep 2022\n",
            "Passport\n",
            "AD4934810\n",
            "Jakarta\n",
            "15 Agt 2017\n",
            "15 Agt 2022\n",
            "· CERTIFICATE OF COMPETENCY\n",
            "Type of Certificate\n",
            "Certificate Number\n",
            "Place/ Date of Issued\n",
            "Ratings as Able Seafarer Deck\n",
            "61229384960948340983\n",
            "Samarinda, 15 Feb 2010\n",
            "· CERTIFICATE OF PROFICIENCY\n",
            "Type of Certificate\n",
            "Certificate Number\n",
            "Place/ Date of Issued\n",
            "Basic Safety Training (BST)\n",
            "61229393896094834394\n",
            "Samarinda, 18 Des 2009\n",
            "Medical First Aid (MEFA)\n",
            "61229384960948348749\n",
            "Samarinda, 4 Jan 2009\n",
            "Advanced Fire Fighting (AFF)\n",
            "61229124960948334873\n",
            "Samarinda, 9 Jan 2009\n",
            "Security Awareness Training\n",
            "(SDSD)\n",
            "61222834960948340980\n",
            "Samarinda 18 Jan 2009\n",
            "Proficiency in Survival Craft &\n",
            "Rescue Boats (SCRB)\n",
            "61223483974948340902\n",
            "Samarinda 4 Feb 2009\n",
            ".\n",
            "SEA SERVICE\n",
            "Name of Vessel\n",
            "Type of Vessel\n",
            "Rank\n",
            "Flag\n",
            "Sign on\n",
            "Sign Off\n",
            "KMP. Mutiara\n",
            "Tug Boat\n",
            "AB\n",
            "Indonesia\n",
            "14.10.2009\n",
            "15.03.2010\n",
            "KM. Amburito\n",
            "Passenger\n",
            "Servant\n",
            "Indonesia\n",
            "03.05.2010\n",
            "12.07.2012\n",
            "VTC Tuo 21\n",
            "Tug Boat...\n",
            "---------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 6. Prepare and Send Request to Azure OpenAI GPT-4o\n",
        "\n",
        "def encode_image_to_base64(image_bytes):\n",
        "    \"\"\"Encodes image bytes to a base64 string.\"\"\"\n",
        "    return base64.b64encode(image_bytes).decode('utf-8')\n",
        "\n",
        "# Initialize dictionary to store final results\n",
        "extracted_kv_pairs = None\n",
        "messages = None\n",
        "gpt_request_ready = False\n",
        "\n",
        "if openai_client and image_bytes and image_mime_type:\n",
        "    print(\"\\n--- Preparing request for GPT-4o ---\")\n",
        "\n",
        "    base64_image = encode_image_to_base64(image_bytes)\n",
        "    image_data_uri = f\"data:{image_mime_type};base64,{base64_image}\"\n",
        "    print(f\"Image encoded as data URI (Type: {image_mime_type}).\")\n",
        "\n",
        "    system_prompt = \"You are an AI assistant specialized in extracting structured key-value pairs from images using the provided image and associated text context.\"\n",
        "\n",
        "    user_prompt_template = \"\"\"\n",
        "    Analyze the provided image and the accompanying text extracted from its layout (which includes numbered points like 1-13).\n",
        "    Your goal is to extract all distinct key-value pairs present in the form image, using both the visual information and the provided text context.\n",
        "    Format the output as a single JSON object.\n",
        "\n",
        "    Detailed Instructions:\n",
        "    1.  **Structure around Numbered Points:** Use the numbered points (e.g., 1, 2, 3... 13) visible in the form and present in the text context as a primary guide for structuring the information. Group related sub-information under the main point's label.\n",
        "    2.  **Key Naming:** Create JSON keys based on the field labels found in the form. Clean the keys by removing leading numbers and punctuation (e.g., '1. Name of Sponsor' should become 'Name of Sponsor', '7A. (Proposed) Indication for Use' should become 'Proposed Indication for Use (7A)' or similar descriptive key).\n",
        "    3.  **Value Extraction:** Extract the corresponding data entered or selected for each field.\n",
        "    4.  **Checkboxes/Radio Buttons:** For groups of options associated with a question (e.g., points 6B, 7C, 7D, 8, 11, 12, 13):\n",
        "        *   Identify the text label of the option that is clearly marked as **selected or checked or ticketed**.\n",
        "        *   Use this selected label as the value for the corresponding key (e.g., \"IND Type (6B)\": \"Research\", \"Phase of Clinical Investigation\": \"Phase 2\").\n",
        "        *   If **no option** within a specific checkbox/radio button group appears to be selected, represent the value as `null` or an empty string `\"\"`.\n",
        "        *   Do **not** include the labels of unselected options.\n",
        "    5.  **Sub-points & Nesting:**\n",
        "        *   For multi-part fields like addresses (point 3), create a nested JSON object (e.g., \"Sponsor Address\": {{\"Street Address\": ..., \"City\": ...}}).  <-- Escaped inner brackets\n",
        "        *   For other lettered sub-points (like 6A/6B, 7A/7B/7C/7D), use descriptive keys incorporating the sub-point identifier as shown in instruction 2. Group conceptually related sub-points if it makes sense (e.g., questions 7A, 7B, 7C, 7D all relate to the indication).\n",
        "    6.  **Blank Fields:** If a field designed for text input is visibly empty or contains only generic placeholder text (like 'If previously assigned', 'Include country code...'), represent its value as `null` or an empty string `\"\"`.\n",
        "    7.  **Accuracy:** Be precise. Extract only information clearly present in the form. If unsure about a field or its value, it's better to omit the key-value pair.\n",
        "    8.  **Output Format:** Return **only** the final JSON object, starting with `{{` and ending with `}}`. Do not include any explanations or introductory text. <-- Escaped brackets\n",
        "\n",
        "    Extracted Text Context (from Layout model - use this to help interpret the image):\n",
        "    ---\n",
        "    {text_content}\n",
        "    ---\n",
        "    \"\"\"\n",
        "\n",
        "    current_extracted_text = extracted_text if not extracted_text.startswith(\"Error:\") else \"Text extraction failed or was skipped.\"\n",
        "    user_prompt = user_prompt_template.format(text_content=current_extracted_text)\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": user_prompt},\n",
        "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_data_uri}}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "    print(\"GPT-4o request payload prepared.\")\n",
        "    gpt_request_ready = True\n",
        "else:\n",
        "    print(\"\\nSkipping GPT-4o preparation: Missing OpenAI client, image data, or MIME type.\")\n",
        "    messages = None\n",
        "    gpt_request_ready = False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poCw-fZq2JyB",
        "outputId": "79213a01-bdb4-4fb7-86d3-5f0481422789"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Preparing request for GPT-4o ---\n",
            "Image encoded as data URI (Type: image/png).\n",
            "GPT-4o request payload prepared.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if openai_client and gpt_request_ready and messages:\n",
        "    print(\"\\n--- Sending request to Azure OpenAI GPT-4o ---\")\n",
        "    try:\n",
        "        response = openai_client.chat.completions.create(\n",
        "            model=openai_deployment_name,\n",
        "            messages=messages,\n",
        "            max_tokens=2500,\n",
        "            temperature=0.1,\n",
        "            response_format={\"type\": \"json_object\"} # Enforce JSON output\n",
        "        )\n",
        "\n",
        "        if response.choices and response.choices[0].message and response.choices[0].message.content:\n",
        "            json_string = response.choices[0].message.content\n",
        "            print(\"\\n--- Raw GPT-4o Response (JSON String) ---\")\n",
        "            print(json_string)\n",
        "            print(\"------------------------------------------\")\n",
        "\n",
        "            try:\n",
        "                extracted_kv_pairs = json.loads(json_string)\n",
        "                print(\"\\nSuccessfully parsed JSON output from GPT-4o.\")\n",
        "            except json.JSONDecodeError as json_err:\n",
        "                print(f\"\\nError: GPT-4o response format ('json_object') failed or returned non-JSON despite the setting. Error: {json_err}\")\n",
        "                print(\"Raw output was:\", json_string)\n",
        "                extracted_kv_pairs = {\"error\": \"Failed to parse GPT-4o JSON output\", \"raw_output\": json_string}\n",
        "        else:\n",
        "            print(\"\\nError: No valid content received in GPT-4o response.\")\n",
        "            print(\"Full Response Object:\", response)\n",
        "            extracted_kv_pairs = {\"error\": \"No content received from GPT-4o.\", \"response_object\": str(response)}\n",
        "\n",
        "    except openai.APIConnectionError as e:\n",
        "        print(f\"Connection Error during Azure OpenAI call: {e}\")\n",
        "        extracted_kv_pairs = {\"error\": f\"Azure OpenAI API Connection Error: {e}\"}\n",
        "    except openai.RateLimitError as e:\n",
        "        print(f\"Rate Limit Error during Azure OpenAI call: {e}\")\n",
        "        extracted_kv_pairs = {\"error\": f\"Azure OpenAI API Rate Limit Error: {e}\"}\n",
        "    except openai.BadRequestError as e:\n",
        "         print(f\"Bad Request Error during Azure OpenAI call: {e}\")\n",
        "         extracted_kv_pairs = {\"error\": f\"Azure OpenAI API Bad Request Error: {e}\"}\n",
        "    except openai.APIError as e:\n",
        "        print(f\"Generic API Error during Azure OpenAI call: {e}\")\n",
        "        extracted_kv_pairs = {\"error\": f\"Azure OpenAI API Error: {e}\"}\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during Azure OpenAI call: {e}\")\n",
        "        extracted_kv_pairs = {\"error\": f\"Unexpected error during OpenAI call: {e}\"}\n",
        "\n",
        "else:\n",
        "    print(\"\\nSkipping Azure OpenAI call. Prerequisites not met (check client, image, messages).\")\n",
        "    if not extracted_kv_pairs:\n",
        "      extracted_kv_pairs = {\"error\": \"Prerequisites not met for OpenAI call.\"}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GjlqoeX2L29",
        "outputId": "395788fe-7a81-46f0-ca82-402480004b3a",
        "collapsed": true
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Sending request to Azure OpenAI GPT-4o ---\n",
            "\n",
            "--- Raw GPT-4o Response (JSON String) ---\n",
            "{\n",
            "  \"Personal Data\": {\n",
            "    \"Full Name\": \"Boni Rustami\",\n",
            "    \"Rank\": \"Cook\",\n",
            "    \"Place and Date of Birth\": \"Samarinda, 10 Juni 1990\",\n",
            "    \"Address\": \"JI Cempaka No 15, Samarinda\",\n",
            "    \"Marital Status\": \"Married\",\n",
            "    \"Nationality\": \"Indonesia\",\n",
            "    \"Religion\": \"Moslem\",\n",
            "    \"Telephone\": \"082931023940\",\n",
            "    \"Email\": \"boni.rustami@cakemail.com\"\n",
            "  },\n",
            "  \"Document Travels\": {\n",
            "    \"Seaman Book\": {\n",
            "      \"Number\": \"F18273909\",\n",
            "      \"Issued At\": \"Samarinda\",\n",
            "      \"Issued Date\": \"18 Sep 2019\",\n",
            "      \"Expire Date\": \"18 Sep 2022\"\n",
            "    },\n",
            "    \"Passport\": {\n",
            "      \"Number\": \"AD4934810\",\n",
            "      \"Issued At\": \"Jakarta\",\n",
            "      \"Issued Date\": \"15 Agt 2017\",\n",
            "      \"Expire Date\": \"15 Agt 2022\"\n",
            "    }\n",
            "  },\n",
            "  \"Certificate of Competency\": {\n",
            "    \"Ratings as Able Seafarer Deck\": {\n",
            "      \"Certificate Number\": \"61229384960948340983\",\n",
            "      \"Place and Date of Issued\": \"Samarinda, 15 Feb 2010\"\n",
            "    }\n",
            "  },\n",
            "  \"Certificate of Proficiency\": {\n",
            "    \"Basic Safety Training (BST)\": {\n",
            "      \"Certificate Number\": \"61229393896094834394\",\n",
            "      \"Place and Date of Issued\": \"Samarinda, 18 Des 2009\"\n",
            "    },\n",
            "    \"Medical First Aid (MEFA)\": {\n",
            "      \"Certificate Number\": \"61229384960948348749\",\n",
            "      \"Place and Date of Issued\": \"Samarinda, 4 Jan 2009\"\n",
            "    },\n",
            "    \"Advanced Fire Fighting (AFF)\": {\n",
            "      \"Certificate Number\": \"61229124960948334873\",\n",
            "      \"Place and Date of Issued\": \"Samarinda, 9 Jan 2009\"\n",
            "    },\n",
            "    \"Security Awareness Training (SDSD)\": {\n",
            "      \"Certificate Number\": \"61222834960948340980\",\n",
            "      \"Place and Date of Issued\": \"Samarinda, 18 Jan 2009\"\n",
            "    },\n",
            "    \"Proficiency in Survival Craft and Rescue Boats (SCRB)\": {\n",
            "      \"Certificate Number\": \"61223483974948340902\",\n",
            "      \"Place and Date of Issued\": \"Samarinda, 4 Feb 2009\"\n",
            "    }\n",
            "  },\n",
            "  \"Sea Service\": [\n",
            "    {\n",
            "      \"Name of Vessel\": \"KMP. Mutiara\",\n",
            "      \"Type of Vessel\": \"Tug Boat\",\n",
            "      \"Rank\": \"AB\",\n",
            "      \"Flag\": \"Indonesia\",\n",
            "      \"Sign On\": \"14.10.2009\",\n",
            "      \"Sign Off\": \"15.03.2010\"\n",
            "    },\n",
            "    {\n",
            "      \"Name of Vessel\": \"KM. Amburito\",\n",
            "      \"Type of Vessel\": \"Passenger\",\n",
            "      \"Rank\": \"Servant\",\n",
            "      \"Flag\": \"Indonesia\",\n",
            "      \"Sign On\": \"03.05.2010\",\n",
            "      \"Sign Off\": \"12.07.2012\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "------------------------------------------\n",
            "\n",
            "Successfully parsed JSON output from GPT-4o.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Final Extracted Key-Value Pairs (JSON) ---\")\n",
        "if isinstance(extracted_kv_pairs, dict):\n",
        "    print(json.dumps(extracted_kv_pairs, indent=2))\n",
        "elif extracted_kv_pairs:\n",
        "     print(extracted_kv_pairs)\n",
        "else:\n",
        "    print(\"No key-value pairs were successfully extracted or an error occurred.\")\n",
        "print(\"---------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf60HQgO2WNc",
        "outputId": "ca45a7c3-3146-4579-bfb1-dd00f5210416"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Final Extracted Key-Value Pairs (JSON) ---\n",
            "{\n",
            "  \"Personal Data\": {\n",
            "    \"Full Name\": \"Boni Rustami\",\n",
            "    \"Rank\": \"Cook\",\n",
            "    \"Place and Date of Birth\": \"Samarinda, 10 Juni 1990\",\n",
            "    \"Address\": \"JI Cempaka No 15, Samarinda\",\n",
            "    \"Marital Status\": \"Married\",\n",
            "    \"Nationality\": \"Indonesia\",\n",
            "    \"Religion\": \"Moslem\",\n",
            "    \"Telephone\": \"082931023940\",\n",
            "    \"Email\": \"boni.rustami@cakemail.com\"\n",
            "  },\n",
            "  \"Document Travels\": {\n",
            "    \"Seaman Book\": {\n",
            "      \"Number\": \"F18273909\",\n",
            "      \"Issued At\": \"Samarinda\",\n",
            "      \"Issued Date\": \"18 Sep 2019\",\n",
            "      \"Expire Date\": \"18 Sep 2022\"\n",
            "    },\n",
            "    \"Passport\": {\n",
            "      \"Number\": \"AD4934810\",\n",
            "      \"Issued At\": \"Jakarta\",\n",
            "      \"Issued Date\": \"15 Agt 2017\",\n",
            "      \"Expire Date\": \"15 Agt 2022\"\n",
            "    }\n",
            "  },\n",
            "  \"Certificate of Competency\": {\n",
            "    \"Ratings as Able Seafarer Deck\": {\n",
            "      \"Certificate Number\": \"61229384960948340983\",\n",
            "      \"Place and Date of Issued\": \"Samarinda, 15 Feb 2010\"\n",
            "    }\n",
            "  },\n",
            "  \"Certificate of Proficiency\": {\n",
            "    \"Basic Safety Training (BST)\": {\n",
            "      \"Certificate Number\": \"61229393896094834394\",\n",
            "      \"Place and Date of Issued\": \"Samarinda, 18 Des 2009\"\n",
            "    },\n",
            "    \"Medical First Aid (MEFA)\": {\n",
            "      \"Certificate Number\": \"61229384960948348749\",\n",
            "      \"Place and Date of Issued\": \"Samarinda, 4 Jan 2009\"\n",
            "    },\n",
            "    \"Advanced Fire Fighting (AFF)\": {\n",
            "      \"Certificate Number\": \"61229124960948334873\",\n",
            "      \"Place and Date of Issued\": \"Samarinda, 9 Jan 2009\"\n",
            "    },\n",
            "    \"Security Awareness Training (SDSD)\": {\n",
            "      \"Certificate Number\": \"61222834960948340980\",\n",
            "      \"Place and Date of Issued\": \"Samarinda, 18 Jan 2009\"\n",
            "    },\n",
            "    \"Proficiency in Survival Craft and Rescue Boats (SCRB)\": {\n",
            "      \"Certificate Number\": \"61223483974948340902\",\n",
            "      \"Place and Date of Issued\": \"Samarinda, 4 Feb 2009\"\n",
            "    }\n",
            "  },\n",
            "  \"Sea Service\": [\n",
            "    {\n",
            "      \"Name of Vessel\": \"KMP. Mutiara\",\n",
            "      \"Type of Vessel\": \"Tug Boat\",\n",
            "      \"Rank\": \"AB\",\n",
            "      \"Flag\": \"Indonesia\",\n",
            "      \"Sign On\": \"14.10.2009\",\n",
            "      \"Sign Off\": \"15.03.2010\"\n",
            "    },\n",
            "    {\n",
            "      \"Name of Vessel\": \"KM. Amburito\",\n",
            "      \"Type of Vessel\": \"Passenger\",\n",
            "      \"Rank\": \"Servant\",\n",
            "      \"Flag\": \"Indonesia\",\n",
            "      \"Sign On\": \"03.05.2010\",\n",
            "      \"Sign Off\": \"12.07.2012\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "---------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PLng0cabrfuG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}